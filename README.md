**Huffman Encoding**
========

<i>Background</i>
=

Coming up to the end of our 3rd year, we were asked to program and implement our own huffman encoding algorithm. It was developed over a number of weeks (among other projects). For this project we received an A.

<i>About</i>
=====

(Taken from http://www.webopedia.com/TERM/H/Huffman_compression.html)

"Also known as Huffman encoding, an algorithm for the lossless compression of files based on the frequency of occurrence of a symbol in the file that is being compressed. The Huffman algorithm is based on statistical coding, which means that the probability of a symbol has a direct bearing on the length of its representation. The more probable the occurrence of a symbol is, the shorter will be its bit-size representation. In any file, certain characters are used more than others. Using binary representation, the number of bits required to represent each character depends upon the number of characters that have to be represented. Using one bit we can represent two characters, i.e., 0 represents the first character and 1 represents the second character. Using two bits we can represent four characters, and so on.
Unlike ASCII code, which is a fixed-length code using seven bits per character, Huffman compression is a variable-length coding system that assigns smaller codes for more frequently used characters and larger codes for less frequently used characters in order to reduce the size of files being compressed and transferred."


<i>Compiling The Code</i>
==================

Compiling is relativily straightforward. It should just compile straight away if it was downloaded as is.
